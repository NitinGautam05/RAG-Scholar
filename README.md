# RAG-Based Chatbot for Research Papers

## ğŸ“Œ Project Overview
This project is a **Retrieval-Augmented Generation (RAG) chatbot** designed to process and answer queries from **research papers (PDFs)**. It extracts relevant information from scientific documents containing **text, tables, images, and formulas** to provide meaningful responses.

## ğŸš€ Features
- **PDF Processing**: Extracts and preprocesses content from research papers.
- **Embeddings & Vector Search**: Uses **sentence-transformers/all-MiniLM-L6-v2** for embedding generation and **ChromaDB** for efficient vector storage and retrieval.
- **LLM Integration**: Powered by **TinyLlama-1.1B-Chat-v1.0** via **Hugging Face API** for contextual answers.
- **Efficient Query Handling**: Retrieves the most relevant document chunks before passing them to the LLM.
- **Scalable & Modular**: Clean and structured code for easy modifications and improvements.

## ğŸ› ï¸ Tech Stack
- **Python** (Primary Language)
- **LangChain** (Framework for RAG)
- **ChromaDB** (Vector Database)
- **Hugging Face API** (LLM & Embeddings)
- **PyMuPDF** (PDF Processing)
- **Streamlit** (For deployment)

## ğŸ“‚ Project Structure
```
ğŸ“ rag-chatbot
â”‚â”€â”€ ğŸ“‚ data                # Stores processed PDF data
â”‚â”€â”€ ğŸ“‚ DB                  # ChromaDB vector storage
â”‚â”€â”€ ğŸ“‚ src                 # Source code
â”‚â”€â”€ requirements.txt       # Dependencies
â”‚â”€â”€ README.md              # Project Documentation
```

